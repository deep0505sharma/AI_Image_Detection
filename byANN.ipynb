{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>...</th>\n",
       "      <th>f_1190</th>\n",
       "      <th>f_1191</th>\n",
       "      <th>f_1192</th>\n",
       "      <th>f_1193</th>\n",
       "      <th>f_1194</th>\n",
       "      <th>f_1195</th>\n",
       "      <th>f_1196</th>\n",
       "      <th>f_1197</th>\n",
       "      <th>f_1198</th>\n",
       "      <th>f_1199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-2.033875</td>\n",
       "      <td>0.978446</td>\n",
       "      <td>-0.142131</td>\n",
       "      <td>-0.177117</td>\n",
       "      <td>-1.470684</td>\n",
       "      <td>1.669562</td>\n",
       "      <td>-0.196530</td>\n",
       "      <td>-0.125239</td>\n",
       "      <td>-0.452284</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.111266</td>\n",
       "      <td>0.716084</td>\n",
       "      <td>0.060039</td>\n",
       "      <td>0.301279</td>\n",
       "      <td>-1.174846</td>\n",
       "      <td>-1.076498</td>\n",
       "      <td>-0.069452</td>\n",
       "      <td>-0.604012</td>\n",
       "      <td>-2.179176</td>\n",
       "      <td>0.558003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.348835</td>\n",
       "      <td>0.294815</td>\n",
       "      <td>-0.557577</td>\n",
       "      <td>-2.020773</td>\n",
       "      <td>-1.234715</td>\n",
       "      <td>1.633930</td>\n",
       "      <td>-1.680658</td>\n",
       "      <td>-0.358146</td>\n",
       "      <td>0.166122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.735240</td>\n",
       "      <td>0.829781</td>\n",
       "      <td>1.521941</td>\n",
       "      <td>1.347946</td>\n",
       "      <td>0.754505</td>\n",
       "      <td>1.330642</td>\n",
       "      <td>-0.754453</td>\n",
       "      <td>0.582956</td>\n",
       "      <td>0.252671</td>\n",
       "      <td>1.495870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.113248</td>\n",
       "      <td>-0.607726</td>\n",
       "      <td>-0.947791</td>\n",
       "      <td>0.830851</td>\n",
       "      <td>0.998291</td>\n",
       "      <td>0.498321</td>\n",
       "      <td>-1.493958</td>\n",
       "      <td>0.789572</td>\n",
       "      <td>-1.311018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104698</td>\n",
       "      <td>0.616189</td>\n",
       "      <td>-1.035953</td>\n",
       "      <td>2.111387</td>\n",
       "      <td>-0.984415</td>\n",
       "      <td>1.148076</td>\n",
       "      <td>-1.433554</td>\n",
       "      <td>0.243372</td>\n",
       "      <td>0.170083</td>\n",
       "      <td>1.274795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.223321</td>\n",
       "      <td>-0.479048</td>\n",
       "      <td>-1.925789</td>\n",
       "      <td>1.680377</td>\n",
       "      <td>0.021840</td>\n",
       "      <td>-1.453307</td>\n",
       "      <td>0.605559</td>\n",
       "      <td>-0.019024</td>\n",
       "      <td>1.065448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360237</td>\n",
       "      <td>-1.957863</td>\n",
       "      <td>-0.123384</td>\n",
       "      <td>1.505329</td>\n",
       "      <td>0.660290</td>\n",
       "      <td>-1.769443</td>\n",
       "      <td>-0.547756</td>\n",
       "      <td>-0.568122</td>\n",
       "      <td>0.244645</td>\n",
       "      <td>0.982116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.160109</td>\n",
       "      <td>0.422684</td>\n",
       "      <td>-0.308029</td>\n",
       "      <td>0.227744</td>\n",
       "      <td>0.432854</td>\n",
       "      <td>0.608348</td>\n",
       "      <td>0.193832</td>\n",
       "      <td>1.035091</td>\n",
       "      <td>-0.538868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.416629</td>\n",
       "      <td>1.441766</td>\n",
       "      <td>0.212572</td>\n",
       "      <td>-0.994721</td>\n",
       "      <td>1.143999</td>\n",
       "      <td>-2.166923</td>\n",
       "      <td>-1.199248</td>\n",
       "      <td>-1.028636</td>\n",
       "      <td>0.752791</td>\n",
       "      <td>0.317169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels       f_0       f_1       f_2       f_3       f_4       f_5  \\\n",
       "0       0 -2.033875  0.978446 -0.142131 -0.177117 -1.470684  1.669562   \n",
       "1       1 -0.348835  0.294815 -0.557577 -2.020773 -1.234715  1.633930   \n",
       "2       1  0.113248 -0.607726 -0.947791  0.830851  0.998291  0.498321   \n",
       "3       0  1.223321 -0.479048 -1.925789  1.680377  0.021840 -1.453307   \n",
       "4       0  0.160109  0.422684 -0.308029  0.227744  0.432854  0.608348   \n",
       "\n",
       "        f_6       f_7       f_8  ...    f_1190    f_1191    f_1192    f_1193  \\\n",
       "0 -0.196530 -0.125239 -0.452284  ... -1.111266  0.716084  0.060039  0.301279   \n",
       "1 -1.680658 -0.358146  0.166122  ...  0.735240  0.829781  1.521941  1.347946   \n",
       "2 -1.493958  0.789572 -1.311018  ...  0.104698  0.616189 -1.035953  2.111387   \n",
       "3  0.605559 -0.019024  1.065448  ...  0.360237 -1.957863 -0.123384  1.505329   \n",
       "4  0.193832  1.035091 -0.538868  ...  0.416629  1.441766  0.212572 -0.994721   \n",
       "\n",
       "     f_1194    f_1195    f_1196    f_1197    f_1198    f_1199  \n",
       "0 -1.174846 -1.076498 -0.069452 -0.604012 -2.179176  0.558003  \n",
       "1  0.754505  1.330642 -0.754453  0.582956  0.252671  1.495870  \n",
       "2 -0.984415  1.148076 -1.433554  0.243372  0.170083  1.274795  \n",
       "3  0.660290 -1.769443 -0.547756 -0.568122  0.244645  0.982116  \n",
       "4  1.143999 -2.166923 -1.199248 -1.028636  0.752791  0.317169  \n",
       "\n",
       "[5 rows x 1201 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('labels',axis = 1)\n",
    "Y = df['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4200, 1200), (1050, 1200), (4200,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train,test,Y_train,Y_tests = train_test_split(X,Y, test_size=0.2, random_state = 20113046)\n",
    "train.shape,test.shape,Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "train = sc.fit_transform(train)\n",
    "test= sc.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for Model Building\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow_addons.metrics import RSquare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/*I have chosen the hidden layers to be 4 as our dataset is large and number of neuron units is decided using the closest power of 2 to the sqrt of the previous input neuron units as it is the most optimal.\n",
    "Hence, sqrt(1200)=36 around and sqrt(36)=6 and so on. As it is a bnary classification problem, I have \n",
    "used sigmoid activation function in the output layer*/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Creating a Model - Breast Cancer Model\n",
    "model = Sequential()\n",
    "\n",
    "# 2. Defining Architecture\n",
    "model.add(Dense(units=36, activation = 'relu',input_dim=1200))\n",
    "model.add(Dense(units=6, activation = 'relu'))\n",
    "model.add(Dense(units=2, activation = 'relu'))\n",
    "model.add(Dense(units=1, activation = 'sigmoid')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "132/132 [==============================] - 2s 4ms/step - loss: 0.4264 - accuracy: 0.7869\n",
      "Epoch 2/100\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.3159 - accuracy: 0.8762\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.2332 - accuracy: 0.9352\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.1757 - accuracy: 0.9760\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.1432 - accuracy: 0.9902\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.1252 - accuracy: 0.9938\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.1113 - accuracy: 0.9957\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.1016 - accuracy: 0.9967\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0916 - accuracy: 0.9976\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0849 - accuracy: 0.9971\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0773 - accuracy: 0.9976\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0713 - accuracy: 0.9976\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0662 - accuracy: 0.9976\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0613 - accuracy: 0.9976\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0571 - accuracy: 0.9976\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0534 - accuracy: 0.9976\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0500 - accuracy: 0.9976\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0469 - accuracy: 0.9979\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0440 - accuracy: 0.9979\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0413 - accuracy: 0.9979\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0389 - accuracy: 0.9979\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0369 - accuracy: 0.9979\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0350 - accuracy: 0.9979\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0333 - accuracy: 0.9979\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0316 - accuracy: 0.9979\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0301 - accuracy: 0.9979\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0290 - accuracy: 0.9979\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0276 - accuracy: 0.9979\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0452 - accuracy: 0.9912\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.1718 - accuracy: 0.9455\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0579 - accuracy: 0.9871\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0273 - accuracy: 0.9979\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0228 - accuracy: 0.9983\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0215 - accuracy: 0.9983\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0205 - accuracy: 0.9983\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0197 - accuracy: 0.9983\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0190 - accuracy: 0.9983\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0183 - accuracy: 0.9983\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0177 - accuracy: 0.9983\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0171 - accuracy: 0.9983\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0165 - accuracy: 0.9983\n",
      "Epoch 42/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0160 - accuracy: 0.9983\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0157 - accuracy: 0.9983\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0144 - accuracy: 0.9986\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0140 - accuracy: 0.9986\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0136 - accuracy: 0.9986\n",
      "Epoch 47/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0132 - accuracy: 0.9986\n",
      "Epoch 48/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0129 - accuracy: 0.9986\n",
      "Epoch 49/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0126 - accuracy: 0.9986\n",
      "Epoch 50/100\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0123 - accuracy: 0.9986\n",
      "Epoch 51/100\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0120 - accuracy: 0.9986\n",
      "Epoch 52/100\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0118 - accuracy: 0.9986\n",
      "Epoch 53/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0115 - accuracy: 0.9986\n",
      "Epoch 54/100\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0113 - accuracy: 0.9986\n",
      "Epoch 55/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0111 - accuracy: 0.9986\n",
      "Epoch 56/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0110 - accuracy: 0.9986\n",
      "Epoch 57/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0108 - accuracy: 0.9986\n",
      "Epoch 58/100\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0106 - accuracy: 0.9986\n",
      "Epoch 59/100\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0105 - accuracy: 0.9986\n",
      "Epoch 60/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0104 - accuracy: 0.9986\n",
      "Epoch 61/100\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0102 - accuracy: 0.9986\n",
      "Epoch 62/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0101 - accuracy: 0.9986\n",
      "Epoch 63/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0100 - accuracy: 0.9986\n",
      "Epoch 64/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0099 - accuracy: 0.9986\n",
      "Epoch 65/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0099 - accuracy: 0.9986\n",
      "Epoch 66/100\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 0.0098 - accuracy: 0.9986\n",
      "Epoch 67/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0097 - accuracy: 0.9986\n",
      "Epoch 68/100\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0096 - accuracy: 0.9986\n",
      "Epoch 69/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0096 - accuracy: 0.9986\n",
      "Epoch 70/100\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0095 - accuracy: 0.9986\n",
      "Epoch 71/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0095 - accuracy: 0.9986\n",
      "Epoch 72/100\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0094 - accuracy: 0.9986\n",
      "Epoch 73/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0094 - accuracy: 0.9986\n",
      "Epoch 74/100\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 0.0094 - accuracy: 0.9986\n",
      "Epoch 75/100\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 0.0093 - accuracy: 0.9986\n",
      "Epoch 76/100\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 0.0093 - accuracy: 0.9986\n",
      "Epoch 77/100\n",
      "132/132 [==============================] - 1s 8ms/step - loss: 0.0093 - accuracy: 0.9986\n",
      "Epoch 78/100\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 0.0092 - accuracy: 0.9986\n",
      "Epoch 79/100\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 0.0092 - accuracy: 0.9986\n",
      "Epoch 80/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0092 - accuracy: 0.9986\n",
      "Epoch 81/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0092 - accuracy: 0.9986\n",
      "Epoch 82/100\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 0.0092 - accuracy: 0.9986\n",
      "Epoch 83/100\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 0.0091 - accuracy: 0.9986\n",
      "Epoch 84/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0091 - accuracy: 0.9986\n",
      "Epoch 85/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0091 - accuracy: 0.9986\n",
      "Epoch 86/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0091 - accuracy: 0.9986\n",
      "Epoch 87/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0091 - accuracy: 0.9986\n",
      "Epoch 88/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0091 - accuracy: 0.9986\n",
      "Epoch 89/100\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0090 - accuracy: 0.9986\n",
      "Epoch 90/100\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0090 - accuracy: 0.9986\n",
      "Epoch 91/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0090 - accuracy: 0.9986\n",
      "Epoch 92/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0090 - accuracy: 0.9986\n",
      "Epoch 93/100\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0090 - accuracy: 0.9986\n",
      "Epoch 94/100\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0090 - accuracy: 0.9986\n",
      "Epoch 95/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0090 - accuracy: 0.9986\n",
      "Epoch 96/100\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0090 - accuracy: 0.9986\n",
      "Epoch 97/100\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0090 - accuracy: 0.9986\n",
      "Epoch 98/100\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0093 - accuracy: 0.9983\n",
      "Epoch 99/100\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0318 - accuracy: 0.9929\n",
      "Epoch 100/100\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.1262 - accuracy: 0.9638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27fe3d4f880>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train, Y_train, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.1293 - accuracy: 0.7848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1292937994003296, 0.784761905670166]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(test)\n",
    "score = model.evaluate(test, Y_tests)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rsquared value is: 0.09560287961437863\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(Y_tests, predictions)\n",
    "print('The rsquared value is: ' + str(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"ANN.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x27fe79538e0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# importing required libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "  \n",
    "# reading the image\n",
    "testImage = img.imread('nn.jpg')\n",
    "# modifying the shape of the image\n",
    "modifiedImage = testImage[:,1500:3000, :]\n",
    "  \n",
    "# displaying the image\n",
    "plt.imshow(modifiedImage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/*TO display the image of architecture of ANN applied using PIL*/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    " \n",
    "# creating a object\n",
    "im = Image.open(\"nn.jpg\")\n",
    " \n",
    "im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 4ms/step\n",
      "[[0.0000000e+00]\n",
      " [9.3652123e-01]\n",
      " [7.8626303e-03]\n",
      " ...\n",
      " [9.9220693e-01]\n",
      " [0.0000000e+00]\n",
      " [8.9408049e-06]]\n"
     ]
    }
   ],
   "source": [
    "predict_x=model.predict(test) \n",
    "print(predict_x)\n",
    "classes_x=np.argmax(predict_x,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct=0 #ct variable store number of label 1 in the generated predicted labels of test dataset\n",
    "for i in range(1050):\n",
    "    if classes_x[i]==1:\n",
    "        ct+=1\n",
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1050, 1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00],\n",
       "       [9.3652123e-01],\n",
       "       [7.8626303e-03],\n",
       "       ...,\n",
       "       [9.9220693e-01],\n",
       "       [0.0000000e+00],\n",
       "       [8.9408049e-06]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = np.asarray(predict_x)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1050,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = yhat[:,0]\n",
    "yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0000000e+00, 9.3652123e-01, 7.8626303e-03, ..., 9.9220693e-01,\n",
       "       0.0000000e+00, 8.9408049e-06], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00786263"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., ..., 1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1050):\n",
    "    if yhat[i]<=0.06:\n",
    "        yhat[i]=0.0\n",
    "    else:\n",
    "        yhat[i]=1.0\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 1, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_class = yhat.astype('i')\n",
    "y_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1050,)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "426"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct=0 #ct variable store number of label 1 in the generated predicted labels of test dataset\n",
    "for i in range(1050):\n",
    "    if y_class[i]==1:\n",
    "        ct+=1\n",
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.750476\n",
      "Precision: 0.532864\n",
      "Recall: 0.782759\n",
      "F1 score: 0.634078\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(Y_tests, y_class)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(Y_tests, y_class)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(Y_tests, y_class)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(Y_tests, y_class)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>...</th>\n",
       "      <th>f_1190</th>\n",
       "      <th>f_1191</th>\n",
       "      <th>f_1192</th>\n",
       "      <th>f_1193</th>\n",
       "      <th>f_1194</th>\n",
       "      <th>f_1195</th>\n",
       "      <th>f_1196</th>\n",
       "      <th>f_1197</th>\n",
       "      <th>f_1198</th>\n",
       "      <th>f_1199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-3.388242</td>\n",
       "      <td>0.868285</td>\n",
       "      <td>-0.427619</td>\n",
       "      <td>-0.678964</td>\n",
       "      <td>-1.625735</td>\n",
       "      <td>0.262761</td>\n",
       "      <td>1.243040</td>\n",
       "      <td>1.537751</td>\n",
       "      <td>-0.352028</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.776403</td>\n",
       "      <td>-0.662884</td>\n",
       "      <td>-0.257091</td>\n",
       "      <td>-1.168413</td>\n",
       "      <td>0.223260</td>\n",
       "      <td>-0.482520</td>\n",
       "      <td>-0.085453</td>\n",
       "      <td>-0.382265</td>\n",
       "      <td>-0.539349</td>\n",
       "      <td>-1.682404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.496920</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.989040</td>\n",
       "      <td>0.451422</td>\n",
       "      <td>0.513516</td>\n",
       "      <td>-0.099658</td>\n",
       "      <td>-1.124326</td>\n",
       "      <td>0.729430</td>\n",
       "      <td>-0.216224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379635</td>\n",
       "      <td>-1.760084</td>\n",
       "      <td>1.125450</td>\n",
       "      <td>-0.328047</td>\n",
       "      <td>-0.880305</td>\n",
       "      <td>-1.257607</td>\n",
       "      <td>0.964312</td>\n",
       "      <td>2.021104</td>\n",
       "      <td>0.655021</td>\n",
       "      <td>-0.423029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.128369</td>\n",
       "      <td>-0.537951</td>\n",
       "      <td>2.544358</td>\n",
       "      <td>1.165254</td>\n",
       "      <td>-1.904994</td>\n",
       "      <td>0.776961</td>\n",
       "      <td>-0.495768</td>\n",
       "      <td>0.060111</td>\n",
       "      <td>-1.418468</td>\n",
       "      <td>...</td>\n",
       "      <td>1.165254</td>\n",
       "      <td>-1.373589</td>\n",
       "      <td>-0.483701</td>\n",
       "      <td>-0.964782</td>\n",
       "      <td>-0.869555</td>\n",
       "      <td>0.066040</td>\n",
       "      <td>-0.444567</td>\n",
       "      <td>-0.531935</td>\n",
       "      <td>-0.878660</td>\n",
       "      <td>1.099488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.051253</td>\n",
       "      <td>1.746814</td>\n",
       "      <td>0.681177</td>\n",
       "      <td>1.844524</td>\n",
       "      <td>-0.327977</td>\n",
       "      <td>1.226839</td>\n",
       "      <td>-0.085519</td>\n",
       "      <td>0.379008</td>\n",
       "      <td>-1.003667</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.442288</td>\n",
       "      <td>-2.794472</td>\n",
       "      <td>-0.763468</td>\n",
       "      <td>-0.789832</td>\n",
       "      <td>-0.113209</td>\n",
       "      <td>-2.703150</td>\n",
       "      <td>-2.058728</td>\n",
       "      <td>1.070627</td>\n",
       "      <td>-0.458045</td>\n",
       "      <td>-0.435825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.423209</td>\n",
       "      <td>-0.983594</td>\n",
       "      <td>-1.694170</td>\n",
       "      <td>1.197507</td>\n",
       "      <td>1.044211</td>\n",
       "      <td>0.518777</td>\n",
       "      <td>-0.298612</td>\n",
       "      <td>-0.365174</td>\n",
       "      <td>0.738447</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.624450</td>\n",
       "      <td>-3.200223</td>\n",
       "      <td>0.711422</td>\n",
       "      <td>-0.190394</td>\n",
       "      <td>0.337224</td>\n",
       "      <td>-1.656639</td>\n",
       "      <td>0.707360</td>\n",
       "      <td>-0.562290</td>\n",
       "      <td>1.471181</td>\n",
       "      <td>-0.192000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       f_0       f_1       f_2       f_3       f_4       f_5       f_6  \\\n",
       "0   1 -3.388242  0.868285 -0.427619 -0.678964 -1.625735  0.262761  1.243040   \n",
       "1   2 -0.496920  0.952381  0.989040  0.451422  0.513516 -0.099658 -1.124326   \n",
       "2   3  1.128369 -0.537951  2.544358  1.165254 -1.904994  0.776961 -0.495768   \n",
       "3   4  0.051253  1.746814  0.681177  1.844524 -0.327977  1.226839 -0.085519   \n",
       "4   5  1.423209 -0.983594 -1.694170  1.197507  1.044211  0.518777 -0.298612   \n",
       "\n",
       "        f_7       f_8  ...    f_1190    f_1191    f_1192    f_1193    f_1194  \\\n",
       "0  1.537751 -0.352028  ... -0.776403 -0.662884 -0.257091 -1.168413  0.223260   \n",
       "1  0.729430 -0.216224  ...  0.379635 -1.760084  1.125450 -0.328047 -0.880305   \n",
       "2  0.060111 -1.418468  ...  1.165254 -1.373589 -0.483701 -0.964782 -0.869555   \n",
       "3  0.379008 -1.003667  ... -0.442288 -2.794472 -0.763468 -0.789832 -0.113209   \n",
       "4 -0.365174  0.738447  ... -2.624450 -3.200223  0.711422 -0.190394  0.337224   \n",
       "\n",
       "     f_1195    f_1196    f_1197    f_1198    f_1199  \n",
       "0 -0.482520 -0.085453 -0.382265 -0.539349 -1.682404  \n",
       "1 -1.257607  0.964312  2.021104  0.655021 -0.423029  \n",
       "2  0.066040 -0.444567 -0.531935 -0.878660  1.099488  \n",
       "3 -2.703150 -2.058728  1.070627 -0.458045 -0.435825  \n",
       "4 -1.656639  0.707360 -0.562290  1.471181 -0.192000  \n",
       "\n",
       "[5 rows x 1201 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"test.csv\")\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2250, 1200)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = df2.drop(\"id\",axis=1)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 1s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_ans = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5829626 ],\n",
       "       [0.00808257],\n",
       "       [0.9867478 ],\n",
       "       ...,\n",
       "       [0.99220693],\n",
       "       [0.        ],\n",
       "       [0.99220693]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2250,)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_ans = Y_ans[:,0]\n",
    "Y_ans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5829626 , 0.00808257, 0.9867478 , ..., 0.99220693, 0.        ,\n",
       "       0.99220693], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = np.asarray(Y_ans)\n",
    "yhat.shape\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., ..., 1., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(2250):\n",
    "    if yhat[i]<=0.65:\n",
    "        yhat[i]=0\n",
    "    else:\n",
    "        yhat[i]=1   \n",
    "yhat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 0, 1], dtype=int32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_res = yhat.astype(\"i\")\n",
    "y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2250, 2)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = np.empty((2250,2))\n",
    "rows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_rows = rows.astype('i')\n",
    "new_rows.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2250):\n",
    "    new_rows[i][0]=i+1\n",
    "    new_rows[i][1]=y_res[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing to CSV\n",
    "\n",
    "\n",
    "import csv\n",
    "\t\n",
    "# field names\n",
    "fields = ['id', 'labels']\n",
    "\t\n",
    "rows = new_rows\n",
    "\t\n",
    "# name of csv file\n",
    "filename = \"solutionbyANN.csv\"\n",
    "\t\n",
    "# writing to csv file \n",
    "with open(filename, 'w',newline = '') as csvfile: \n",
    "    # creating a csv writer object \n",
    "    csvwriter = csv.writer(csvfile) \n",
    "        \n",
    "    # writing the fields \n",
    "    csvwriter.writerow(fields) \n",
    "        \n",
    "    # writing the data rows \n",
    "    csvwriter.writerows(rows)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "afb734500600fd355917ca529030176ea0ca205570884b88f2f6f7d791fd3fbe"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
